---
title: OpenAI 宫斗背后：人工智能的哲学之争
date: 2023-12-27 16:35:29
tags: 
- 哲学
- 人工智能
summary: 2022 年开始，人工智能急速发展。2023 年末，我们已经看到 AGI 已经近在眼前。关于“知识”、“思维”、“自我意识”这些问题好像正在从科幻电影慢慢进入到我们的生活中。那么哲学家们，又是如何试图解答这些问题的呢？
draft: false
---

# 0 前言

2023 年就快结束了，这段时间人工智能最火的新闻就是 OpenAI CEO 山姆·奥特曼重归董事会。这不仅仅是 OpenAI 内部的政治斗争，**同时也是两种哲学流派的纷争**，这篇文章我们就以哲学的角度看看当今人工智能的发展。

人工智能是一个非常有意思的领域，我非常喜欢。刚好最近找了一本《人工智能：现代方法》来看，在翻到第一章的时候，作者介绍了人工智能背后的哲学原理，这些哲学问题讨论了关于“知识”、“思维”、“自我意识”等主题，很有趣。

# 1 哲学对人工智能的启发

哲学是一切现代科学的基础，当今社会是一个以科学技术进步主导的社会，而科学背后的哲学基础就显得尤为重要。

人工智能领域属于计算机科学范畴，背后有精深的哲学理论。它研究的是“用机器模仿人类的智慧”，那么关于“知识”、“思维”这些概念就引出了一系列的哲学问题。

人工智能中的哲学问题主要有四个：

- 人类知识的结论可以用形式化的规则表示吗？
- 思维是怎么从大脑里产生的？
- 知识从哪里来？
- 我们有了知识，那么这些知识如何引导我们的行为？（知识和行为之间的关系是什么？）

本文将从这四个点出发，结合人工智能的一些概念，看看哲学家们是如何思考这些问题的。

# 2 专家系统和三段论：用规则表示知识

人工智能领域中有一个子学科是“专家系统”。

简单地讲，专家系统就是用**一套逻辑规则来帮助处理专业问题的系统**。

例如在化学实验中，专家系统可以根据质谱波峰来推断分子式，它用预先设定好的一系列规则作为依据，而这样的规则来自于科学家的经验。

早在古希腊时期，亚里士多德就就提出了三段论。它用一个很经典的形式描述了逻辑推导过程：

> 如果所有人都是必死的（大前提），并且所有希腊人都是人（小前提），那么所有希腊人都是必死的（结论）。

于是，只要有了正确大前提和小前提，那么就能得到正确的结论。

三段论对人工智能的启发，在于它用规则化的方式描述了现实世界的逻辑结构，使得我们可以用数学的和程序的方法来描述世界。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-19-41-13.png)

<center>
  <small>
    《雅典学院》中的柏拉图（左、红衣服）和亚里士多德（右、蓝衣服）。柏拉图手指指天，**象征形而上学的抽象哲学**，亚里士多德手掌向地，表示**更务实的科学研究方法。**（图片来自于网络）
  </small>
</center>

# 3 思维是怎么产生的？

如今 ChatGPT 等一众语言模型让我们刷新了对人工智能的认识。

GPT 的回答逻辑缜密，思维清晰，就好像和真人对话一样，这让我们不禁有一种错觉：好像人工智能也有了意识。

哲学家们一直在思考**意识从哪里来**。究竟是什么让人类的”大脑“拥有了自我意识呢？

## 3.1 硅基生命和《利维坦》：思维就像机器

如果生命是一台精密的机器，那么我们的思维只是机器上的一部分而已，机器和人也许就没有明确的分界线。

“碳基生命”和“硅基生命”的相似性也许超过我们的想象。

著名的政治家霍布斯在《利维坦》里描述了一个巨大而复杂的国家机器。同时，他也假设国家是一种“会思考的机器”：

> 心脏无非是发条，神经只是游丝，而关节不过是一些齿轮。
>
> 推理就是一种计算，也就是相加减。
>
> —— 《利维坦》

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-47-26.png)

<center>
  <small>《银翼杀手2049》：如何辨别自己是人类还是仿生人？（图片来自于网络）</small>
</center>

## 3.2 机器的自我意识和二元论：身体和心灵的独立性

如果身体和心灵是分离的，那么人工智能的自我意识是不是也可以独立于机器存在呢？

笛卡尔提出的“二元论”就试图探明身体和心灵之间的关系，他认为**“身体”和“心灵”是分开的**。

这与基督教的思想不谋而合。基督教认为人有“灵魂”，死后灵魂将会上天堂或者下地狱。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-18-41.png)

<center>
  <small>勒内·笛卡尔（图片来自于网络）</small>
</center>

## 3.3 神经网络与唯物主义：世界不神秘，一切都是物理定律

当前火爆的神经网络的原理其实也十分简单。

GPT 背后，不过是一堆加减乘除的算法和一连串数据，即使复杂如“多头注意力”和“反向传播”等理论，从底层看，也是简单的。

正是这些简单的物理和数学定律，构成了说不清道不明的自我意识。

唯物主义的哲学家们认为：**这个世界上没有什么神秘的东西，我们的思维只不过是从“物理定律”运作的结果。**我们的意识底层就是一连串复杂的神经和电信号活动。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-17-40.png)

<center>
  <small>人工智能神经网络之间的连接，像大脑神经元的连接一样。（图片来自于网络）</small>
</center>

# 4 知识来自于哪里？

## 4.1 “训练”与经验主义：知识来自于经验

训练神经网络需要数据，这些数据是“神经网络大脑”的“经验”。良好的数据集才能保证良好的训练效果。

机器学习领域有一个说法叫做“垃圾进，垃圾出”(Garbage in, garbage out)，说的就是如果原始数据不佳，那么训练出的模型就一定不好，这就是经验的重要性。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-30-12.png)

<center>
  <small>（图片来自于网络）</small>
</center>

弗朗西斯·培根和约翰·洛克是经验主义的代表。洛克认为“**知识归根结底来自于经验**”。而经验主义则认为“**知识来自于感觉的体验，我们思想的形成受到感官知识的影响**”。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-11-13-22.png)

<center>
  <small> 弗朗西斯·培根（图片来自于网络）</small>
</center>

## 4.2 模型与归纳法：知识来自于重复的事物

我们知道神经网络的数学基础是统计学，就是从大量的数据中找到“重复的规律”，总结出可以代表这种规律的“模型”，然后用这个模型来“推理”得到预测结果。

这样的方法就是“归纳法”，它是一种从特殊到一般的思维方法。通俗地讲，就是“**从重复的现象中总结规律，共性，然后发现知识**”。

归纳法最早也是亚里士多德提出的。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-31-06.png)

<center>
  <small>（图片来自于网络）</small>
</center>

## 4.3 逻辑实证主义：知识是数学和逻辑的

逻辑实证主义的代表是维也纳学派，著名的哲学家维特根斯坦虽然不属于维也纳学派，但是他一直保持着非常紧密的联系。

逻辑实证主义认为，人类的知识是“理性”的，是**可以用数学和逻辑来描述的**。

在逻辑实证主义的指导下，我们就有了表示知识的方法：数学和逻辑。

神经网络中的一个神经元其实就是一组算式，我们可以认为，里面包含了一个“知识”。

举个例子，这个知识可以是“图片里是否有猫？”或者“现在这个单词和幽默这个情绪有关吗？”，当输入的图片里面真的包含了猫或者输入了一则幽默的笑话时，这个神经元就会被激活，从宏观上看，就是神经网络理解了关于”猫“和”幽默“的概念。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-19-39-19.png)

<center>
  <small>
    一个简化的全连接神经网络，图片中的圆圈代表神经元，可以认为其中“蕴含”了一则知识，当神经元收到了一个输入以后，如果和神经元的知识相关，那么该神经元就会被“激活”（图片来自于网络）
  </small>
</center>

# 5 知识如何指导行为？

## 5.1 “行为”与亚里士多德：行为要和知识相关

再次请出伟大的亚里士多德。**他认为行为十分重要，而知识要指导行为。**

在定义好目标之后，更要关注我们怎么达成目标，也就是行为。如果没有行为，那么知识就没有意义。

这就像我们在学习了很多知识之后，一定要拿来使用，如果不使用，那么学再多的知识也是无用的。

> 我们考虑的不是目的，而是那些达到目的的东西 —— 《尼各马克伦理学》

亚里士多德的思路对于机器人领域非常有启发性。

就拿扫地机器人来说，扫描后的家中地图便是“知识”，机器人根据地图来做决策：“现在是应该左转还是右转？这个区域扫完之后应该到哪个区域？”。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-33-53.png)

## 5.2 “目标”与功利主义：“效用”的最大化

边沁是功利主义的代表人物，他认为：“理性的决策应该是效用最大化的”。

在“电车难题”中，功利主义者就会认为，我们应该去搬动道闸让死伤人数最小。他们认为，**所有对社会有利的决策都应该以结果为准**。

在机器学习的训练过程中，工程师会使用一个“损失函数”来衡量人工智能模型的有效性。

例如，对于一个识别猫图片的模型来说，“能够正确识别图片中的猫”就是它的“效用”。衡量模型的结果往往是单一化的，这体现了功利主义的行为方式。

为什么有时候我们觉得人工智能“很傻”？就是因为它对目标的理解非常单一，虽然事情好像也是做对了，但是并不符合我们的要求，给我们一种“人工智障” 的感觉。

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-23-35.png)

<center>
  <small>
    让 GPT4 生成一个“很多很多很多人快乐的吃很多很多很多汤圆”的图片，可见 GPT
    对于输入的理解是非常片面的，只是生成了很多“快乐”的人和很多汤圆。（图片来自于网络）
  </small>
</center>

## 5.3 “超级对齐”和义务伦理学：普世价值观决定事物的正确性

与功利主义相反，以康德为代表的义务伦理学主义者认为，不能仅仅根据结果来判断事情有没有做对，而应该根据“道德”，或者说是“社会普世价值观”。

现在，对人工智能“对齐”的要求就是义务伦理学的体现。所谓“对齐”就是调整人工智能，使其符合人类的价值观。

2023 年底在“OpenAI 宫斗”事件中也出现了两种思潮之争：

一派是以马斯克为代表的保守派，**认为我们应该对人工智能做“超级对齐”，让它们符合人类道德价值观。**而另一边，**以山姆·奥特曼为代表的激进派，则认为人类应该拥抱科技进步，因为历史证明科技进步对于人类社会的进步总是有好处的。**

![](/static/blog/2023-12-27-philosophy-of-ai/2023-12-29-10-22-14.png)

<center>
  <small>山姆·奥特曼被赶出 OpenAI 董事会之后，戴着访客证进入 OpenAI 的办公大楼。</small>
</center>

# 6 结语

太阳底下没有新鲜事，当前在人类社会中发生的事，都已经被古代和近代的哲学家思考过一遍了。

引用吴军博士的一句话：

> “历史总在重演，科技永远向前”。

这对于我们计算机专业的理工生说非常有启发。虽然我们学习的是工科，解决的主要是工程问题，但是了解一些文科知识也是非常重要的，不但有助于我们能更好的理解人类社会，而且能够让我们更好的看清楚科技发展的趋势。

不知道是否对你也有同样的启发，希望这篇文章能够帮你了解人工智能领域的一些哲学基础。

# 参考文献

- 《人工智能：现代方法》- 1.2 人工智能的基础 - 1.2.1 哲学
- 托马斯·霍布斯 -《利维坦》 - 序章
- 亚里士多德 -《尼各马克伦理学》 - 第三卷
- 义务伦理学：[康德义务主义 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E5%BA%B7%E5%BE%B7%E7%BE%A9%E5%8B%99%E4%B8%BB%E7%BE%A9)
- [三段论 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E4%B8%89%E6%AE%B5%E8%AB%96)
- [唯物主义 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E5%94%AF%E7%89%A9%E4%B8%BB%E4%B9%89)
- [经验主义 - 维基百科，自由的百科全书](https://zh.wikipedia.org/wiki/%E7%BB%8F%E9%AA%8C%E4%B8%BB%E4%B9%89)
- [山姆·奥尔特曼现身OpenAI总部未明确去留 激进与保守路线之争将持续](https://www.yicai.com/news/101907581.html?code=101908075)
- [DNN－全连接神经网络](https://www.dohkoai.com/usr/show?id=33)
- [画一家人在吃汤圆，逐渐离谱…](https://www.xiaohongshu.com/explore/6589a601000000001c0126c7?app_platform=ios&app_version=8.18&share_from_user_hidden=true&type=video&author_share=1&xhsshare=WeixinSession&appuid=5ccdb237000000001200d736&apptime=1703668002)
